{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn import init\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(os.path.normpath('/home/md359230/DeepLearning/assignment1/data/fruits-360/Training'),\n",
    "                                  transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                          batch_size=128,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.ImageFolder(os.path.normpath('/home/md359230/DeepLearning/assignment1/data/fruits-360/Test'),\n",
    "                                  transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                          batch_size=128,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 100, 100])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fruitImShow(img):\n",
    "    npimg = img.numpy()\n",
    "    img = plt.imshow(npimg)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "for i, images in enumerate(train_loader):\n",
    "    if i >= 0:\n",
    "        print(images[0].squeeze().size())\n",
    "        fruitImShow(np.transpose(images[0][0,:,:,:], [1, 2, 0]))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "example, no = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 100, 100])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 100, 100])\n",
      "torch.Size([128, 8, 96, 96])\n",
      "torch.Size([128, 8, 48, 48])\n",
      "torch.Size([128, 16, 38, 38])\n",
      "torch.Size([4, 32, 23104])\n",
      "torch.Size([128, 16, 19, 19])\n"
     ]
    }
   ],
   "source": [
    "tmp = example\n",
    "print(tmp.size())\n",
    "tmp = nn.Conv2d(3, 8, 5)(tmp)\n",
    "print(tmp.size())\n",
    "tmp = nn.MaxPool2d((2,2))(tmp)\n",
    "print(tmp.size())\n",
    "tmp = nn.Conv2d(8, 16, 11)(tmp)\n",
    "print(tmp.size())\n",
    "print(tmp.view(4,-1, 16 * 38 * 38).size())\n",
    "tmp = nn.MaxPool2d(2,2)(tmp)\n",
    "print(tmp.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=5776, out_features=100, bias=True)\n",
       "  (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer(16*19*19, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49191\n"
     ]
    }
   ],
   "source": [
    "! ls -R /home/md359230/DeepLearning/assignment1/data/fruits-360/Training/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16707\n"
     ]
    }
   ],
   "source": [
    "! ls -R /home/md359230/DeepLearning/assignment1/data/fruits-360/Test/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384.3046875"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "49191 / 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.8341,  0.1073],\n",
      "         [-1.5900,  0.7515]],\n",
      "\n",
      "        [[-0.2715,  0.9093],\n",
      "         [ 0.0181,  0.0836]]])\n",
      "tensor([0.0257, 0.1849])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2,2)\n",
    "print(x)\n",
    "print(torch.mean(x, (1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.3592,  0.9586, -2.2687, -0.7316],\n",
      "          [-0.1976, -1.3876, -1.7334,  1.0312],\n",
      "          [-1.3025, -1.4624,  0.6063,  1.0155],\n",
      "          [-0.9894, -0.8540, -1.0822, -0.0915]],\n",
      "\n",
      "         [[-0.0558, -0.6707, -2.2107,  0.2486],\n",
      "          [-0.6671,  1.2670, -0.5990, -0.6199],\n",
      "          [ 0.3946, -0.4155,  0.6211, -0.0213],\n",
      "          [ 1.4263,  0.2343, -0.3309, -0.4443]],\n",
      "\n",
      "         [[-0.3917, -1.1598, -0.9039,  0.5166],\n",
      "          [ 1.7122, -0.4550, -1.0423, -0.7295],\n",
      "          [-1.9230, -0.4065,  0.0323,  0.6236],\n",
      "          [ 0.3059,  1.6485, -0.9048,  0.3842]]],\n",
      "\n",
      "\n",
      "        [[[-0.0501, -0.1945,  0.5907, -0.1499],\n",
      "          [-2.2273,  1.7362,  0.4117, -1.0932],\n",
      "          [ 1.5655, -0.3937, -1.8002,  1.6674],\n",
      "          [ 0.7181,  0.1063,  0.5773, -0.4593]],\n",
      "\n",
      "         [[ 0.3989, -1.8571,  2.1592,  1.3154],\n",
      "          [ 0.8036,  0.7200,  0.6123,  0.7596],\n",
      "          [ 1.6692, -0.4298,  0.1296, -0.5667],\n",
      "          [ 1.2675,  0.4753, -0.9747,  0.0288]],\n",
      "\n",
      "         [[ 1.0556, -2.0220,  0.5488,  0.4790],\n",
      "          [ 1.0878,  0.7545,  1.2298, -0.4737],\n",
      "          [ 1.2273, -0.8325,  0.7691,  0.2577],\n",
      "          [ 0.2311, -0.9121,  0.7354,  0.9760]]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,3, 4, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBatchNormalization(torch.nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(MyBatchNormalization, self).__init__()\n",
    "        self.num_features = num_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        r = x.matmul(self.weight.t())\n",
    "        r += self.bias\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchNorm(x):\n",
    "    print(x.size())\n",
    "    means = torch.mean(x, 1, keep_dim=True)\n",
    "    print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 4])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "mean() received an invalid combination of arguments - got (Tensor, int, keep_dim=bool), but expected one of:\n * (Tensor input)\n * (Tensor input, torch.dtype dtype)\n * (Tensor input, tuple of ints dim, torch.dtype dtype, Tensor out)\n * (Tensor input, tuple of ints dim, bool keepdim, torch.dtype dtype, Tensor out)\n * (Tensor input, tuple of ints dim, bool keepdim, Tensor out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-227-d61ac8ae6de6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatchNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-226-57a4b3258d75>\u001b[0m in \u001b[0;36mbatchNorm\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbatchNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: mean() received an invalid combination of arguments - got (Tensor, int, keep_dim=bool), but expected one of:\n * (Tensor input)\n * (Tensor input, torch.dtype dtype)\n * (Tensor input, tuple of ints dim, torch.dtype dtype, Tensor out)\n * (Tensor input, tuple of ints dim, bool keepdim, torch.dtype dtype, Tensor out)\n * (Tensor input, tuple of ints dim, bool keepdim, Tensor out)\n"
     ]
    }
   ],
   "source": [
    "batchNorm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network and trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_layer(in_channels, \n",
    "                        out_channels,\n",
    "                        kernel_size,\n",
    "                        batchnorm_module='default', \n",
    "                        *args, \n",
    "                        **kwargs): \n",
    "    \"\"\"Function for flexible construction of convolutional layers for the network.\n",
    "    \n",
    "    :param in_channels: Number of input channels.\n",
    "    :param out_channels: Number of channels produced by the output.\n",
    "    :param kernel_size: Kernel size for convolutional layer.\n",
    "    :param batchnorm_module: Must be in ('default', 'custom'). Should Pytorch's or own BN \n",
    "    normalization be used?\n",
    "    :param *args: Additional arguments to pass to convolutional layer.\n",
    "    :param **kwargs: Additional arguments to pass to convolutional layer.\n",
    "    :return: Layer consisting of convolution, batch normalization and max pooling.\"\"\"\n",
    "    batchnorm_modules = nn.ModuleDict([\n",
    "        ['default', nn.BatchNorm2d(out_channels)],\n",
    "        ['custom', MyBatchNormalization(out_channels)]\n",
    "    ])\n",
    "    \n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size, *args, **kwargs),\n",
    "        batchnorm_modules[batchnorm_module],\n",
    "        nn.MaxPool2d((2,2))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_layer(in_features, \n",
    "                 out_feautres, \n",
    "                 batchnorm_module='default',\n",
    "                 activation_function='relu', \n",
    "                 *args, \n",
    "                 **kwargs):\n",
    "    \"\"\"Function for flexible construction of full-connected layers for the network.\n",
    "    \n",
    "    :param in_features: Size of input layer.\n",
    "    :param out_features: Size of output layer.\n",
    "    :param batchnorm_module: Must be in ('default', 'custom'). Should Pytorch's or own BN \n",
    "    normalization be used?\n",
    "    :param activation_fuction: Must be in ('relu', 'lrelu', 'sigmoid'). Which activation\n",
    "    function should be used?\n",
    "    :param *args: Additional arguments to pass to full-connected layer.\n",
    "    :param **kwargs: Additional arguments to pass to full-connected layer.\n",
    "    :return: Layer consisting of full-connected module, batch normalization and activation function.\"\"\"\n",
    "    batchnorm_modules = nn.ModuleDict([\n",
    "        ['default', nn.BatchNorm1d(out_feautres)],\n",
    "        ['custom', MyBatchNormalization(out_feautres)]\n",
    "    ])\n",
    "    \n",
    "    activation_functions = nn.ModuleDict([\n",
    "        ['lrelu', nn.LeakyReLU()],\n",
    "        ['relu', nn.ReLU()],\n",
    "        ['sigmoid', nn.Sigmoid()]\n",
    "    ])\n",
    "\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features, out_feautres, *args, **kwargs),\n",
    "        batchnorm_modules[batchnorm_module],\n",
    "        activation_functions[activation_function]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalStack(nn.Module):\n",
    "    def __init__(self, sizes, kernel_sizes, *args, **kwargs):\n",
    "        super(ConvolutionalStack, self).__init__()\n",
    "        self.convolutional_layers = nn.ModuleList([convolutional_layer(in_size, out_size, ker_size, *args, **kwargs)\n",
    "                                                   for in_size, out_size, ker_size in zip(sizes, sizes[1:], kernel_sizes)])\n",
    "    def forward(self, x):\n",
    "        for convolutional_layer in self.convolutional_layers:\n",
    "            x = convolutional_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearStack(nn.Module):\n",
    "    def __init__(self, sizes, n_classes, *args, **kwargs):\n",
    "        super(LinearStack, self).__init__()\n",
    "        self.linear_layers = nn.ModuleList([linear_layer(in_size, out_size, *args, **kwargs)\n",
    "                                                   for in_size, out_size in zip(sizes, sizes[1:])])\n",
    "        self.linear_layers.append(nn.Linear(sizes[-1], n_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for linear_layer in self.linear_layers:\n",
    "            x = linear_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, conv_sizes, kernel_sizes, linear_sizes, n_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = ConvolutionalStack(conv_sizes, kernel_sizes)\n",
    "        self.fc = LinearStack(linear_sizes, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(-1, 16 * 19 * 19)\n",
    "        x = self.fc(x)\n",
    "        x = x.squeeze()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FruitTrainer(object):\n",
    "    def __init__(self, train_data, train_loader, test_data, test_loader):\n",
    "        self.trainset = train_data\n",
    "        self.trainloader = train_loader\n",
    "        \n",
    "        self.testset = test_data\n",
    "        self.testloader = test_loader\n",
    "        \n",
    "    def assess(self, net, test=True):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        if test:\n",
    "            for data in self.testloader:\n",
    "                images, labels = data\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            print('Accuracy of the network on the {} test images: {:2.4f} %'.format(\n",
    "                total, 100 * correct / total))\n",
    "        else:\n",
    "            for data in self.trainloader:\n",
    "                images, labels = data\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            print('Accuracy of the network on the {} train images: {:2.4f} %'.format(\n",
    "                total, 100 * correct / total))            \n",
    "                       \n",
    "    def train(self):\n",
    "        net = Net((3, 8, 16), (5, 11), (16 * 19 * 19, 1000, 500), 95)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=0.05, momentum=0.9)\n",
    "\n",
    "        for epoch in range(4):\n",
    "            running_loss = 0.0\n",
    "            t = time.time()\n",
    "            for i, data in enumerate(self.trainloader, 0):\n",
    "                inputs, labels = data\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 100 == 99:\n",
    "                    print('[%d, %5d] loss: %.4f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 100))\n",
    "                    print('[%d, %5d] Elapsed time: %2.4f s' %\n",
    "                          (epoch + 1, i + 1, time.time() - t))\n",
    "                    running_loss = 0.0\n",
    "                    t = time.time()\n",
    "            \n",
    "            self.assess(net)\n",
    "            self.assess(net, test=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.6463\n",
      "[1,   100] Elapsed time: 34.4545 s\n",
      "[1,   200] loss: 0.1690\n",
      "[1,   200] Elapsed time: 35.1712 s\n",
      "[1,   300] loss: 0.0370\n",
      "[1,   300] Elapsed time: 34.6791 s\n",
      "Accuracy of the network on the 16445 test images: 96.9839 %\n",
      "Accuracy of the network on the 48905 train images: 99.9652 %\n",
      "[2,   100] loss: 0.0121\n",
      "[2,   100] Elapsed time: 34.3910 s\n",
      "[2,   200] loss: 0.0080\n",
      "[2,   200] Elapsed time: 35.6789 s\n",
      "[2,   300] loss: 0.0085\n",
      "[2,   300] Elapsed time: 34.0123 s\n",
      "Accuracy of the network on the 16445 test images: 95.8589 %\n",
      "Accuracy of the network on the 48905 train images: 99.6156 %\n",
      "[3,   100] loss: 0.0124\n",
      "[3,   100] Elapsed time: 33.1980 s\n",
      "[3,   200] loss: 0.0069\n",
      "[3,   200] Elapsed time: 29.0671 s\n",
      "[3,   300] loss: 0.0036\n",
      "[3,   300] Elapsed time: 32.0296 s\n",
      "Accuracy of the network on the 16445 test images: 97.1846 %\n",
      "Accuracy of the network on the 48905 train images: 100.0000 %\n"
     ]
    }
   ],
   "source": [
    "trainer = FruitTrainer(train_data, train_loader, test_data, test_loader)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, -1), (2, 3, -2), (3, 4, -3)]"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (1,2,3,4)\n",
    "b = (-1,-2,-3)\n",
    "list(zip(a, a[1:], b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
