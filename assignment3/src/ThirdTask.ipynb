{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "from string import punctuation\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "from imageio import imwrite\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.parameter as P\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch.nn.utils.rnn as utils_rnn\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23011601\n"
     ]
    }
   ],
   "source": [
    "! cat ../data/task3_train.txt | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_lines = np.random.choice(np.arange(23011601), size=150000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_lines = np.sort(sample_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 157,  181,  343,  609,  618,  655, 1115, 1132, 1151, 1296])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_no = 0\n",
    "with open('/home/md359230/DeepLearning/assignment3/data/task3_sample.txt', 'w') as sample_data:\n",
    "    with open('/home/md359230/DeepLearning/assignment3/data/task3_train.txt', 'r') as full_data:\n",
    "        for counter, line in enumerate(full_data):\n",
    "            if line_no < 150000 and counter == sample_lines[line_no]:\n",
    "                line_no += 1\n",
    "                max_word_length = max([len(word) for word in line.split()])\n",
    "                correct_line = True if max_word_length <= 15 else False\n",
    "                if correct_line:\n",
    "                    sample_data.write(line)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000\n"
     ]
    }
   ],
   "source": [
    "print(line_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131723\n"
     ]
    }
   ],
   "source": [
    "! cat ../data/task3_sample.txt | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/md359230/DeepLearning/assignment3/data/task3_sample.txt', 'r') as sample_data:\n",
    "    with open('/home/md359230/DeepLearning/assignment3/data/train.txt', 'w') as train_data:\n",
    "        with open('/home/md359230/DeepLearning/assignment3/data/validation.txt', 'w') as validation_data:\n",
    "            for counter, line in enumerate(sample_data):\n",
    "                if counter < 105378:\n",
    "                    train_data.write(line)            \n",
    "                else:\n",
    "                    validation_data.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105378\n"
     ]
    }
   ],
   "source": [
    "! cat ../data/train.txt | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26345\n"
     ]
    }
   ],
   "source": [
    "! cat ../data/validation.txt | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorpusPreprocessor(object):  \n",
    "    @staticmethod\n",
    "    def transform_text(text):\n",
    "        # Remove EOL character\n",
    "        text = text.replace('\\n', ' ')\n",
    "        \n",
    "        # Remove numbers\n",
    "        numbers = '1234567890'\n",
    "        for number in numbers:\n",
    "            text = text.replace(number, ' ')\n",
    "        \n",
    "        # Remove punctuation\n",
    "        for specialchar in punctuation:\n",
    "            text = text.replace(specialchar, ' ')\n",
    "            \n",
    "        # Remove double spaces\n",
    "        double_spaces = re.compile('\\s+')\n",
    "        text = re.sub(double_spaces, ' ', text)\n",
    "        \n",
    "        # Trim text\n",
    "        words = text.split(' ')\n",
    "        words = [word.lower() for word in words if word]\n",
    "        text = ' '.join(words)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @staticmethod\n",
    "    def mask_text(text, corpus_dictionary):\n",
    "        MASK = 'MASK'\n",
    "        masked_sent = text.split()\n",
    "        selected_word_idx = random.randint(0, len(masked_sent) - 1)\n",
    "        if random.randint(0, 1) == 1:\n",
    "            original_word = masked_sent[selected_word_idx]\n",
    "            masked_sent[selected_word_idx] = MASK\n",
    "            return (masked_sent, original_word, selected_word_idx, 1)\n",
    "        else:\n",
    "            random_word = np.random.choice(corpus_dictionary)\n",
    "            masked_sent[selected_word_idx] = MASK\n",
    "            return (masked_sent, random_word, selected_word_idx, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'afdafs sa sfw gw g gfdsaf j'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CorpusPreprocessor.transform_text('AFDafs  41 2 5$#sa 24 Sfw15 gw g4gfdsaf j.    ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ala', 'MASK', 'kota'], 'aaa', 1, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CorpusPreprocessor.mask_text(CorpusPreprocessor.transform_text('Ala ma kota.'), ['aaa', 'bbb', 'ccc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLPDataSet(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.sentences = []\n",
    "        self.corpus_vocab = []\n",
    "        \n",
    "        # Load corpus from file\n",
    "        chars = set()\n",
    "        with open(file_path, 'r') as raw_data:\n",
    "            for line in raw_data:\n",
    "                line = CorpusPreprocessor.transform_text(line)\n",
    "                chars = chars | set(line)\n",
    "                self.sentences.append(line)\n",
    "        \n",
    "        # Create dict with all letters\n",
    "        self.chars = OrderedDict(zip(chars, (torch.zeros(len(chars)) for _ in range(len(chars)))))\n",
    "        for idx, key in enumerate(self.chars.keys()):\n",
    "            if key != ' ':\n",
    "                self.chars[key][idx] = 1.\n",
    "        \n",
    "        # Fill the dictionary with sample 20%\n",
    "        for sentence in self.sentences[:len(self.sentences) // 5]:\n",
    "            for word in sentence.split():\n",
    "                if len(word) >= 3:\n",
    "                    self.corpus_vocab.append(word)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def _encode_word(self, word):\n",
    "        result = []\n",
    "        if word == 'MASK':\n",
    "            return result\n",
    "        \n",
    "        for letter in word:\n",
    "            result.append(self.chars[letter])\n",
    "    \n",
    "        return result\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sentence, word, idx, label = CorpusPreprocessor.mask_text(self.sentences[idx], self.corpus_vocab)\n",
    "        sentence = [self._encode_word(word) for word in sentence]\n",
    "        word = self._encode_word(word)\n",
    "        idx = torch.LongTensor([idx]).view(1)\n",
    "        label = torch.LongTensor([label]).view(1)\n",
    "        return sentence, word, idx, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = NLPDataSet('/home/md359230/DeepLearning/assignment3/data/train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = NLPDataSet('/home/md359230/DeepLearning/assignment3/data/validation.txt')\n",
    "data_test.chars = data_train.chars.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jego żołnierza i biedę można znaleźć w repertuarze polskich teatrów'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 0, 1, 5, 5, 7, 1, 11, 8, 7]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(len, data_train[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_collate(batch): \n",
    "    def stack_chars(word):\n",
    "        if len(word) > 1:\n",
    "            return torch.stack(word)\n",
    "        else:\n",
    "            if len(word) == 1:\n",
    "                return word[0].view(1, -1)\n",
    "            else:\n",
    "                return torch.zeros(1, 36)\n",
    "    \n",
    "    words = []\n",
    "    sentences = [] \n",
    "    words_length = []\n",
    "    sentences_length = []\n",
    "    idxs = []\n",
    "    labels = [] \n",
    "    for sentence, word, idx, label in batch: \n",
    "        words.append(word)\n",
    "        sentences.append(sentence)\n",
    "        words_length.append(len(word))\n",
    "        sentences_length.append([len(word) if len(word) > 0 else 1 for word in sentence])\n",
    "        idxs.append(idx)\n",
    "        labels.append(label) \n",
    "       \n",
    "    words = [stack_chars(word) for word in words]\n",
    "    words = utils_rnn.pad_sequence(words)\n",
    "    sentences = [utils_rnn.pad_sequence(list(map(stack_chars, sentence))) for sentence in sentences]\n",
    "    words_length = torch.LongTensor(words_length)\n",
    "    sentences_length = [torch.LongTensor(sentence) for sentence in sentences_length]\n",
    "    idxs = torch.stack(idxs)\n",
    "    labels = torch.stack(labels).squeeze(1)\n",
    "    return sentences, sentences_length, words, words_length, idxs,  labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(data_train,\n",
    "                              batch_size=1024,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=nlp_collate,\n",
    "                              num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_test = DataLoader(data_test,\n",
    "                             batch_size=1024,\n",
    "                             shuffle=True,\n",
    "                             collate_fn=nlp_collate,\n",
    "                             num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = next(iter(dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([torch.Size([13, 10, 36]),\n",
       "  torch.Size([13, 23, 36]),\n",
       "  torch.Size([9, 11, 36]),\n",
       "  torch.Size([9, 12, 36]),\n",
       "  torch.Size([10, 4, 36]),\n",
       "  torch.Size([14, 15, 36]),\n",
       "  torch.Size([12, 15, 36]),\n",
       "  torch.Size([12, 9, 36]),\n",
       "  torch.Size([12, 19, 36]),\n",
       "  torch.Size([12, 12, 36]),\n",
       "  torch.Size([12, 21, 36]),\n",
       "  torch.Size([12, 25, 36]),\n",
       "  torch.Size([9, 14, 36]),\n",
       "  torch.Size([15, 17, 36]),\n",
       "  torch.Size([14, 24, 36]),\n",
       "  torch.Size([9, 9, 36])],\n",
       " [tensor(13),\n",
       "  tensor(13),\n",
       "  tensor(9),\n",
       "  tensor(9),\n",
       "  tensor(10),\n",
       "  tensor(14),\n",
       "  tensor(12),\n",
       "  tensor(12),\n",
       "  tensor(12),\n",
       "  tensor(12),\n",
       "  tensor(12),\n",
       "  tensor(12),\n",
       "  tensor(9),\n",
       "  tensor(15),\n",
       "  tensor(14),\n",
       "  tensor(9)])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s.size() for s in example[0]], [max(e) for e in example[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([torch.Size([10]),\n",
       "  torch.Size([23]),\n",
       "  torch.Size([11]),\n",
       "  torch.Size([12]),\n",
       "  torch.Size([4]),\n",
       "  torch.Size([15]),\n",
       "  torch.Size([15]),\n",
       "  torch.Size([9]),\n",
       "  torch.Size([19]),\n",
       "  torch.Size([12]),\n",
       "  torch.Size([21]),\n",
       "  torch.Size([25]),\n",
       "  torch.Size([14]),\n",
       "  torch.Size([17]),\n",
       "  torch.Size([24]),\n",
       "  torch.Size([9])],\n",
       " tensor([[ 1],\n",
       "         [ 7],\n",
       "         [ 5],\n",
       "         [ 0],\n",
       "         [ 2],\n",
       "         [13],\n",
       "         [ 0],\n",
       "         [ 2],\n",
       "         [ 8],\n",
       "         [11],\n",
       "         [17],\n",
       "         [15],\n",
       "         [10],\n",
       "         [ 9],\n",
       "         [20],\n",
       "         [ 2]]))"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e.size() for e in example[1]], example[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i, example in enumerate(data_train):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "CPU times: user 16.7 s, sys: 11.6 s, total: 28.4 s\n",
      "Wall time: 8min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, batch in enumerate(dataloader_train):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_layer(in_features, \n",
    "                 out_features, \n",
    "                 batchnorm_module='default',\n",
    "                 activation_function='relu', \n",
    "                 *args, \n",
    "                 **kwargs):\n",
    "    activation_functions = nn.ModuleDict([\n",
    "        ['lrelu', nn.LeakyReLU()],\n",
    "        ['relu', nn.ReLU()],\n",
    "        ['sigmoid', nn.Sigmoid()]\n",
    "    ])\n",
    "\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features, out_features, *args, **kwargs),\n",
    "        nn.BatchNorm1d(out_features),\n",
    "        activation_functions[activation_function]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearStack(nn.Module):\n",
    "    \"\"\"Class containing implementation of standard linear stack.\n",
    "    \"\"\"\n",
    "    def __init__(self, sizes, n_classes, *args, **kwargs):\n",
    "        super(LinearStack, self).__init__()\n",
    "        self.linear_layers = nn.ModuleList([linear_layer(in_size, out_size, *args, **kwargs)\n",
    "                                                   for in_size, out_size in zip(sizes, sizes[1:])])\n",
    "        self.linear_layers.append(nn.Linear(sizes[-1], n_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Method implemention linear stack forward pass.\n",
    "        :param x: Input tensor.\n",
    "        :return: Processed tensor.\"\"\"\n",
    "        for linear_layer in self.linear_layers:\n",
    "            x = linear_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbedder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(WordEmbedder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=hidden_size)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        words_input, lengths = x\n",
    "        words_input = utils_rnn.pack_padded_sequence(input=words_input, \n",
    "                                               lengths=lengths, \n",
    "                                               enforce_sorted=False)\n",
    "        out, _ = self.lstm(words_input)\n",
    "        result, _ = utils_rnn.pad_packed_sequence(out, \n",
    "                                            total_length=max(lengths).item())\n",
    "        idx = (lengths - 1).view(-1, 1)\\\n",
    "                           .expand(len(lengths), \n",
    "                                   self.hidden_size)\n",
    "        idx = idx.unsqueeze(0)\n",
    "        result = result.gather(0, idx).squeeze(0)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WordEmbedder(36, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = next(iter(dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "example2 = example[2].to(device) \n",
    "example3 = example[3].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model((example2, example3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model((example[2], example[3]))\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, sentences_length = example[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([15, 100]),\n",
       " torch.Size([13, 100]),\n",
       " torch.Size([23, 100]),\n",
       " torch.Size([22, 100]),\n",
       " torch.Size([42, 100]),\n",
       " torch.Size([24, 100]),\n",
       " torch.Size([12, 100]),\n",
       " torch.Size([20, 100]),\n",
       " torch.Size([13, 100]),\n",
       " torch.Size([8, 100]),\n",
       " torch.Size([23, 100]),\n",
       " torch.Size([16, 100]),\n",
       " torch.Size([8, 100]),\n",
       " torch.Size([7, 100]),\n",
       " torch.Size([14, 100]),\n",
       " torch.Size([11, 100])]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = []\n",
    "for idx in range(len(sentences)):\n",
    "    embeddings.append(model((sentences[idx], sentences_length[idx])))\n",
    "\n",
    "[e.size() for e in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainLanguageModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size,\n",
    "                 embedding_size,\n",
    "                 hidden_size, \n",
    "                 linear_sizes, \n",
    "                 n_classes):\n",
    "        super(MainLanguageModel, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.wordembedder = WordEmbedder(input_size=input_size, \n",
    "                                         hidden_size=embedding_size)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            bidirectional=True)\n",
    "        self.fc = LinearStack(linear_sizes, \n",
    "                              n_classes,     \n",
    "                              batchnorm_module='default',\n",
    "                              activation_function='lrelu')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Create embeddings\n",
    "        sentences, sentences_length, words, words_length, idxs = x\n",
    "        embeddings = []\n",
    "        \n",
    "        for idx in range(len(sentences)):\n",
    "            embeddings.append(self.wordembedder((sentences[idx], sentences_length[idx])))\n",
    "                \n",
    "        masked_word_embeddings = self.wordembedder((words, words_length))\n",
    "        \n",
    "        # Feed RNN with sentence batch\n",
    "        lengths = torch.LongTensor([sl.size()[0] for sl in sentences_length])\n",
    "        sentence_batch = utils_rnn.pad_sequence(embeddings)        \n",
    "        sentence_batch = utils_rnn.pack_padded_sequence(input=sentence_batch, \n",
    "                                                        lengths=lengths, \n",
    "                                                        enforce_sorted=False)\n",
    "        \n",
    "        out, _ = self.lstm(sentence_batch)\n",
    "        result, _ = utils_rnn.pad_packed_sequence(out, \n",
    "                                                  total_length=max(lengths).item())\n",
    "        idx = (idxs).view(-1, 1)\\\n",
    "                    .expand(len(lengths), 2 * self.hidden_size)        \n",
    "        idx = idx.unsqueeze(0)\n",
    "        result = result.gather(0, idx).squeeze(0)\n",
    "        \n",
    "        joined_result = torch.cat((result, masked_word_embeddings), dim=1)\n",
    "        joined_result = self.fc(joined_result)\n",
    "            \n",
    "        # Return embeddings, masked_word_embeddings, sentences_length, idxs\n",
    "        return joined_result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'input_size': 36,\n",
    "    'embedding_size': 100,\n",
    "    'hidden_size': 50,\n",
    "    'linear_sizes': (200, 100),\n",
    "    'n_classes': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm = MainLanguageModel(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "mlm = mlm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = next(iter(dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, sentences_length, words, words_length, idxs, labels = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sentence.to(device) for sentence in sentences]\n",
    "sentences_length = [sl.to(device) for sl in sentences_length]\n",
    "words = words.to(device)\n",
    "words_length = words_length.to(device)\n",
    "idxs = idxs.to(device)\n",
    "labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = mlm((sentences, sentences_length, words, words_length, idxs))\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetTrainer(object):\n",
    "    def __init__(self, train_loader, test_loader):\n",
    "        self.trainloader = train_loader\n",
    "        self.testloader = test_loader\n",
    "        \n",
    "    def assess(self, net, test=True, use_gpu=False, device=None):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        loader = self.testloader if test else self.trainloader\n",
    "        for data in loader:\n",
    "            sentences, sentences_length, words, words_length, idxs, labels = data\n",
    "            if device is not None and (device.__str__() != \"cpu\") and use_gpu:\n",
    "                sentences = [sentence.to(device) for sentence in sentences]\n",
    "                sentences_length = [sl.to(device) for sl in sentences_length]\n",
    "                words = words.to(device)\n",
    "                words_length = words_length.to(device)\n",
    "                idxs = idxs.to(device)\n",
    "                labels = labels.to(device)\n",
    "            outputs = net((sentences, sentences_length, words, words_length, idxs))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        dataset_name = 'test' if test else 'train'\n",
    "        print('Accuracy of the network on {} {} sentences: {:2.4f} %'.format(\n",
    "            total, dataset_name, 100 * correct / total))         \n",
    "            \n",
    "    def train(self, \n",
    "              config, \n",
    "              n_epoch=5, \n",
    "              use_gpu=False, \n",
    "              resume_training=False, \n",
    "              net_path=None):\n",
    "        net = MainLanguageModel(**config)\n",
    "        \n",
    "        if resume_training:\n",
    "            net.load_state_dict(torch.load(net_path))          \n",
    "        \n",
    "        if use_gpu:\n",
    "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "            if device.__str__() != \"cpu\":\n",
    "                net.to(device)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(net.parameters(), lr=0.0002, amsgrad=True)\n",
    "\n",
    "        for epoch in range(n_epoch):\n",
    "            running_loss = 0.0\n",
    "            t = time.time()\n",
    "            net.train()\n",
    "            \n",
    "            for i, data in enumerate(self.trainloader, 0):\n",
    "                sentences, sentences_length, words, words_length, idxs,  labels = data\n",
    "                \n",
    "                if use_gpu:\n",
    "                    if(device.__str__() != \"cpu\"):\n",
    "                        sentences = [sentence.to(device) for sentence in sentences]\n",
    "                        sentences_length = [sl.to(device) for sl in sentences_length]\n",
    "                        words = words.to(device)\n",
    "                        words_length = words_length.to(device)\n",
    "                        idxs = idxs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                    \n",
    "                optimizer.zero_grad()\n",
    "                outputs = net((sentences, sentences_length, words, words_length, idxs))\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 10 == 9:\n",
    "                    now = datetime.datetime.now()\n",
    "                    print('[%s , %d, %5d] Loss: %.4f' %\n",
    "                          (now.strftime('%Y-%m-%d %H:%M:%S'), epoch + 1, i + 1, running_loss / 100))\n",
    "                    print('[%s , %d, %5d] Elapsed time: %2.4f s' %\n",
    "                          (now.strftime('%Y-%m-%d %H:%M:%S'), epoch + 1, i + 1, time.time() - t))\n",
    "                    running_loss = 0.0\n",
    "                    t = time.time()\n",
    "            \n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                if use_gpu:\n",
    "                    self.assess(net, use_gpu=True, device=device)\n",
    "                    #self.assess(net, test=False, use_gpu=True, device=device)                \n",
    "                else:\n",
    "                    self.assess(net)\n",
    "                    #self.assess(net, test=False)\n",
    "\n",
    "        return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'input_size': 36,\n",
    "    'embedding_size': 200,\n",
    "    'hidden_size': 100,\n",
    "    'linear_sizes': (400, 200, 100),\n",
    "    'n_classes': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = NetTrainer(dataloader_train, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/md359230/DeepLearning/assignment3/src/model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-06-03 16:17:28 , 1,    10] Loss: 0.0623\n",
      "[2019-06-03 16:17:28 , 1,    10] Elapsed time: 89.4656 s\n",
      "[2019-06-03 16:18:19 , 1,    20] Loss: 0.0622\n",
      "[2019-06-03 16:18:19 , 1,    20] Elapsed time: 51.6113 s\n",
      "[2019-06-03 16:19:18 , 1,    30] Loss: 0.0624\n",
      "[2019-06-03 16:19:18 , 1,    30] Elapsed time: 58.1421 s\n",
      "[2019-06-03 16:20:15 , 1,    40] Loss: 0.0622\n",
      "[2019-06-03 16:20:15 , 1,    40] Elapsed time: 57.3205 s\n",
      "[2019-06-03 16:21:14 , 1,    50] Loss: 0.0619\n",
      "[2019-06-03 16:21:14 , 1,    50] Elapsed time: 58.7944 s\n",
      "[2019-06-03 16:22:10 , 1,    60] Loss: 0.0622\n",
      "[2019-06-03 16:22:10 , 1,    60] Elapsed time: 56.2893 s\n",
      "[2019-06-03 16:23:06 , 1,    70] Loss: 0.0618\n",
      "[2019-06-03 16:23:06 , 1,    70] Elapsed time: 56.4797 s\n",
      "[2019-06-03 16:24:05 , 1,    80] Loss: 0.0615\n",
      "[2019-06-03 16:24:05 , 1,    80] Elapsed time: 58.1032 s\n",
      "[2019-06-03 16:25:02 , 1,    90] Loss: 0.0613\n",
      "[2019-06-03 16:25:02 , 1,    90] Elapsed time: 57.5769 s\n",
      "[2019-06-03 16:26:02 , 1,   100] Loss: 0.0613\n",
      "[2019-06-03 16:26:02 , 1,   100] Elapsed time: 59.5293 s\n",
      "Accuracy of the network on 26345 test sentences: 60.4745 %\n",
      "[2019-06-03 16:29:16 , 2,    10] Loss: 0.0607\n",
      "[2019-06-03 16:29:16 , 2,    10] Elapsed time: 91.6101 s\n",
      "[2019-06-03 16:30:19 , 2,    20] Loss: 0.0608\n",
      "[2019-06-03 16:30:19 , 2,    20] Elapsed time: 62.7845 s\n",
      "[2019-06-03 16:31:19 , 2,    30] Loss: 0.0602\n",
      "[2019-06-03 16:31:19 , 2,    30] Elapsed time: 60.1559 s\n",
      "[2019-06-03 16:32:19 , 2,    40] Loss: 0.0612\n",
      "[2019-06-03 16:32:19 , 2,    40] Elapsed time: 59.5529 s\n",
      "[2019-06-03 16:33:19 , 2,    50] Loss: 0.0609\n",
      "[2019-06-03 16:33:19 , 2,    50] Elapsed time: 60.2875 s\n",
      "[2019-06-03 16:34:18 , 2,    60] Loss: 0.0612\n",
      "[2019-06-03 16:34:18 , 2,    60] Elapsed time: 59.5685 s\n",
      "[2019-06-03 16:35:07 , 2,    70] Loss: 0.0598\n",
      "[2019-06-03 16:35:07 , 2,    70] Elapsed time: 48.9246 s\n",
      "[2019-06-03 16:35:57 , 2,    80] Loss: 0.0600\n",
      "[2019-06-03 16:35:57 , 2,    80] Elapsed time: 49.7425 s\n",
      "[2019-06-03 16:36:49 , 2,    90] Loss: 0.0607\n",
      "[2019-06-03 16:36:49 , 2,    90] Elapsed time: 52.0640 s\n",
      "[2019-06-03 16:37:41 , 2,   100] Loss: 0.0593\n",
      "[2019-06-03 16:37:41 , 2,   100] Elapsed time: 52.1825 s\n",
      "Accuracy of the network on 26345 test sentences: 62.3040 %\n",
      "[2019-06-03 16:40:48 , 3,    10] Loss: 0.0597\n",
      "[2019-06-03 16:40:48 , 3,    10] Elapsed time: 95.6275 s\n",
      "[2019-06-03 16:41:47 , 3,    20] Loss: 0.0600\n",
      "[2019-06-03 16:41:47 , 3,    20] Elapsed time: 58.4225 s\n",
      "[2019-06-03 16:42:44 , 3,    30] Loss: 0.0591\n",
      "[2019-06-03 16:42:44 , 3,    30] Elapsed time: 57.2486 s\n",
      "[2019-06-03 16:43:41 , 3,    40] Loss: 0.0598\n",
      "[2019-06-03 16:43:41 , 3,    40] Elapsed time: 57.2875 s\n",
      "[2019-06-03 16:44:39 , 3,    50] Loss: 0.0595\n",
      "[2019-06-03 16:44:39 , 3,    50] Elapsed time: 57.5418 s\n",
      "[2019-06-03 16:45:37 , 3,    60] Loss: 0.0593\n",
      "[2019-06-03 16:45:37 , 3,    60] Elapsed time: 58.1408 s\n",
      "[2019-06-03 16:46:35 , 3,    70] Loss: 0.0591\n",
      "[2019-06-03 16:46:35 , 3,    70] Elapsed time: 58.6017 s\n",
      "[2019-06-03 16:47:31 , 3,    80] Loss: 0.0584\n",
      "[2019-06-03 16:47:31 , 3,    80] Elapsed time: 55.8684 s\n",
      "[2019-06-03 16:48:28 , 3,    90] Loss: 0.0585\n",
      "[2019-06-03 16:48:28 , 3,    90] Elapsed time: 56.5794 s\n",
      "[2019-06-03 16:49:17 , 3,   100] Loss: 0.0588\n",
      "[2019-06-03 16:49:17 , 3,   100] Elapsed time: 48.8490 s\n",
      "Accuracy of the network on 26345 test sentences: 63.9135 %\n"
     ]
    }
   ],
   "source": [
    "model = trainer.train(config, n_epoch=3, use_gpu=True, resume_training=True, net_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/md359230/DeepLearning/assignment3/src/model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MainLanguageModel(\n",
       "  (wordembedder): WordEmbedder(\n",
       "    (lstm): LSTM(36, 200)\n",
       "  )\n",
       "  (lstm): LSTM(200, 100, bidirectional=True)\n",
       "  (fc): LinearStack(\n",
       "    (linear_layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=400, out_features=200, bias=True)\n",
       "        (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Linear(in_features=200, out_features=100, bias=True)\n",
       "        (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (2): Linear(in_features=100, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded = MainLanguageModel(**config)\n",
    "model_loaded.load_state_dict(torch.load(model_path))\n",
    "model_loaded.eval()\n",
    "model_loaded.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = NetTrainer(dataloader_train, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-06-03 17:20:28 , 1,    10] Loss: 0.0619\n",
      "[2019-06-03 17:20:28 , 1,    10] Elapsed time: 78.7439 s\n",
      "[2019-06-03 17:21:16 , 1,    20] Loss: 0.0617\n",
      "[2019-06-03 17:21:16 , 1,    20] Elapsed time: 47.9956 s\n",
      "[2019-06-03 17:22:05 , 1,    30] Loss: 0.0612\n",
      "[2019-06-03 17:22:05 , 1,    30] Elapsed time: 49.3273 s\n",
      "[2019-06-03 17:22:56 , 1,    40] Loss: 0.0612\n",
      "[2019-06-03 17:22:56 , 1,    40] Elapsed time: 50.4886 s\n",
      "[2019-06-03 17:23:46 , 1,    50] Loss: 0.0613\n",
      "[2019-06-03 17:23:46 , 1,    50] Elapsed time: 49.7222 s\n",
      "[2019-06-03 17:24:33 , 1,    60] Loss: 0.0609\n",
      "[2019-06-03 17:24:33 , 1,    60] Elapsed time: 47.5550 s\n",
      "[2019-06-03 17:25:22 , 1,    70] Loss: 0.0602\n",
      "[2019-06-03 17:25:22 , 1,    70] Elapsed time: 48.4835 s\n",
      "[2019-06-03 17:26:09 , 1,    80] Loss: 0.0608\n",
      "[2019-06-03 17:26:09 , 1,    80] Elapsed time: 47.4304 s\n",
      "[2019-06-03 17:27:00 , 1,    90] Loss: 0.0607\n",
      "[2019-06-03 17:27:00 , 1,    90] Elapsed time: 50.4808 s\n",
      "[2019-06-03 17:27:46 , 1,   100] Loss: 0.0603\n",
      "[2019-06-03 17:27:46 , 1,   100] Elapsed time: 46.5519 s\n",
      "Accuracy of the network on 26345 test sentences: 61.2830 %\n"
     ]
    }
   ],
   "source": [
    "model_loaded = trainer.train(config, n_epoch=3, use_gpu=True, resume_training=True, net_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on 26345 test sentences: 59.3547 %\n"
     ]
    }
   ],
   "source": [
    "trainer.assess(model_loaded, use_gpu=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~63.7616 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network visualzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLPVisualizer(object):\n",
    "    def __init__(self, \n",
    "                 vocabulary, \n",
    "                 dictionary, \n",
    "                 embedder,\n",
    "                 device):\n",
    "        self.vocabulary = vocabulary\n",
    "        self.dictionary = dictionary\n",
    "        self.embedder = embedder\n",
    "        self.device = device\n",
    "        \n",
    "        vocab_lengths = torch.LongTensor([len(word) for word in self.vocabulary])       \n",
    "        vector_vocab = [[self.dictionary[char] for char in word] for word in self.vocabulary]\n",
    "        vector_vocab = [self.stack_chars(word) for word in vector_vocab]\n",
    "        vector_vocab = utils_rnn.pad_sequence(vector_vocab)\n",
    "        vector_vocab, vocab_lengths = vector_vocab.to(self.device), vocab_lengths.to(self.device)\n",
    "        \n",
    "        out = self.embedder((vector_vocab, vocab_lengths))\n",
    "        out = out.cpu()\\\n",
    "                 .detach()\\\n",
    "                 .numpy()\n",
    "        self.tsne = TSNE(n_components=2, \n",
    "                    perplexity=30.0, \n",
    "                    n_iter=1000)\n",
    "        out = self.tsne.fit_transform(out)\n",
    "        self.embeddings = out\n",
    "        \n",
    "    @staticmethod\n",
    "    def stack_chars(word):\n",
    "        if len(word) > 1:\n",
    "            return torch.stack(word)\n",
    "        else:\n",
    "            if len(word) == 1:\n",
    "                return word[0].view(1, -1)\n",
    "            else:\n",
    "                return torch.zeros(1, 36)\n",
    "        \n",
    "    def find_most_similar_word(self, embedding):\n",
    "        return self.vocabulary[np.argmax((self.embeddings @ embedding))]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpv = NLPVisualizer(data_train.corpus_vocab[:20000], data_train.chars, model_loaded.wordembedder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=nlpv.embeddings[:, 0], y=nlpv.embeddings[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oba',\n",
       " 'medale',\n",
       " 'wywalczył',\n",
       " 'strzelaniu',\n",
       " 'karabinu',\n",
       " 'dowolnego',\n",
       " 'trzech',\n",
       " 'pozycjach',\n",
       " 'srebro',\n",
       " 'indywidualnie']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlpv.vocabulary[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wszystkich'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlpv.find_most_similar_word(nlpv.embeddings[1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jeżelibyśmy'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 2\n",
    "nlpv.vocabulary[np.argmax((out @ out[idx, :]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def visualize_words(self):\\n    vocab_lengths = torch.LongTensor([len(word) for word in self.vocabulary])       \\n    vector_vocab = [[self.dictionary[char] for char in word] for word in self.vocabulary]\\n    vector_vocab = [self.stack_chars(word) for word in vector_vocab]\\n    vector_vocab = utils_rnn.pad_sequence(vector_vocab)\\n    vector_vocab, vocab_lengths = vector_vocab.to(self.device), vocab_lengths.to(self.device)\\n    \\n    out = self.embedder((vector_vocab, vocab_lengths))\\n    out = out.cpu().detach().numpy()\\n    out = self.tsne.fit_transform(out)\\n    \\n    return out'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \"\"\"def visualize_words(self):\n",
    "        vocab_lengths = torch.LongTensor([len(word) for word in self.vocabulary])       \n",
    "        vector_vocab = [[self.dictionary[char] for char in word] for word in self.vocabulary]\n",
    "        vector_vocab = [self.stack_chars(word) for word in vector_vocab]\n",
    "        vector_vocab = utils_rnn.pad_sequence(vector_vocab)\n",
    "        vector_vocab, vocab_lengths = vector_vocab.to(self.device), vocab_lengths.to(self.device)\n",
    "        \n",
    "        out = self.embedder((vector_vocab, vocab_lengths))\n",
    "        out = out.cpu().detach().numpy()\n",
    "        out = self.tsne.fit_transform(out)\n",
    "        \n",
    "        return out\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = set()\n",
    "corpus_words = set()\n",
    "lens = list()\n",
    "with open('/home/md359230/DeepLearning/assignment3/data/task3_sample.txt', 'r') as sample_data:\n",
    "    for line in sample_data:\n",
    "        line = CorpusPreprocessor.transform_text(line)\n",
    "        lens.append(len(line))\n",
    "        chars = chars | set(line)\n",
    "        words = line.split()\n",
    "        corpus_words = corpus_words | set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7.0255e+04, 2.5162e+04, 3.7240e+03, 6.8500e+02, 1.3800e+02,\n",
       "        2.6000e+01, 5.0000e+00, 4.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
       " array([   4.,  137.,  270.,  403.,  536.,  669.,  802.,  935., 1068.,\n",
       "        1201., 1334.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'po wybuchu ii wojny światowej podczas kampanii wrześniowej sprawował stanowisko dowódcy pułku piechoty'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = 'Po wybuchu II wojny światowej 1939 podczas kampanii wrześniowej sprawował stanowisko dowódcy 78 pułku piechoty.'\n",
    "cp.transform_text(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        self.dictionary = OrderedDict()\n",
    "        self.corpus_path = corpus_path\n",
    "        with open(corpus_path, 'r') as corpus:\n",
    "            for line in corpus:\n",
    "                self.dictionary[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'afs 41 2 5$#sa 24 Sfw15 gw g4gfdsaf j'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_spaces = re.compile('\\s+')\n",
    "re.sub(double_spaces, ' ', 'afs  41 2 5$#sa 24 Sfw15 gw g4gfdsaf j')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([torch.Size([4, 100]),\n",
       "  torch.Size([6, 100]),\n",
       "  torch.Size([5, 100]),\n",
       "  torch.Size([14, 100]),\n",
       "  torch.Size([9, 100]),\n",
       "  torch.Size([18, 100]),\n",
       "  torch.Size([6, 100]),\n",
       "  torch.Size([22, 100]),\n",
       "  torch.Size([9, 100]),\n",
       "  torch.Size([11, 100]),\n",
       "  torch.Size([6, 100]),\n",
       "  torch.Size([13, 100]),\n",
       "  torch.Size([8, 100]),\n",
       "  torch.Size([6, 100]),\n",
       "  torch.Size([25, 100]),\n",
       "  torch.Size([16, 100])],\n",
       " torch.Size([16, 100]))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o.size() for o in out[0]], out[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_words= out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = torch.LongTensor([o.size()[0] for o in out[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_input = utils_rnn.pad_sequence(out[0])\n",
    "\n",
    "words_input.size()\n",
    "\n",
    "packed_input = utils_rnn.pack_padded_sequence(input=words_input, \n",
    "                                             lengths=lengths, \n",
    "                                             enforce_sorted=False)\n",
    "\n",
    "lstm2 = nn.LSTM(input_size=100,\n",
    "                hidden_size=50,\n",
    "                bidirectional=True)\n",
    "\n",
    "out, _ = lstm2(packed_input)\n",
    "result, _ = utils_rnn.pad_packed_sequence(out, \n",
    "                                    total_length=max(lengths).item())\n",
    "idx = (idxs).view(-1, 1)\\\n",
    "                                     .expand(len(lengths), \n",
    "                                             100)\n",
    "idx = idx.unsqueeze(0)\n",
    "result_final = result.gather(0, idx).squeeze(0)\n",
    "\n",
    "result_final.size()\n",
    "\n",
    "joined_information = torch.cat((result_final, masked_words), dim=1)\n",
    "\n",
    "fc = LinearStack((200, 100), 2)\n",
    "\n",
    "final = fc(joined_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0788,  0.2965],\n",
       "        [ 0.3925,  0.1174],\n",
       "        [ 0.0335, -0.1361],\n",
       "        [ 0.2581,  0.1808],\n",
       "        [ 0.1624,  0.1204],\n",
       "        [ 0.2782,  0.2596],\n",
       "        [-0.0378,  0.1297],\n",
       "        [ 0.5840,  0.2376],\n",
       "        [ 0.2791,  0.1616],\n",
       "        [ 0.5826,  0.6866],\n",
       "        [ 0.0406,  0.0681],\n",
       "        [ 0.5139, -0.0842],\n",
       "        [-0.0675,  0.0903],\n",
       "        [ 0.1305,  0.1092],\n",
       "        [ 0.4054,  0.4469],\n",
       "        [ 0.0595,  0.0318]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6807, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "loss(final, labels.squeeze(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
