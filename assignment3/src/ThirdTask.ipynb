{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "from string import punctuation\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "from imageio import imwrite\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.parameter as P\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch.nn.utils.rnn as utils_rnn\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23011601\n"
     ]
    }
   ],
   "source": [
    "! cat ../data/task3_train.txt | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_lines = np.random.choice(np.arange(23011601), size=150000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_lines = np.sort(sample_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 157,  181,  343,  609,  618,  655, 1115, 1132, 1151, 1296])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_no = 0\n",
    "with open('/home/md359230/DeepLearning/assignment3/data/task3_sample.txt', 'w') as sample_data:\n",
    "    with open('/home/md359230/DeepLearning/assignment3/data/task3_train.txt', 'r') as full_data:\n",
    "        for counter, line in enumerate(full_data):\n",
    "            if line_no < 150000 and counter == sample_lines[line_no]:\n",
    "                line_no += 1\n",
    "                max_word_length = max([len(word) for word in line.split()])\n",
    "                correct_line = True if max_word_length <= 15 else False\n",
    "                if correct_line:\n",
    "                    sample_data.write(line)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000\n"
     ]
    }
   ],
   "source": [
    "print(line_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131723\n"
     ]
    }
   ],
   "source": [
    "! cat ../data/task3_sample.txt | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/md359230/DeepLearning/assignment3/data/task3_sample.txt', 'r') as sample_data:\n",
    "    with open('/home/md359230/DeepLearning/assignment3/data/train.txt', 'w') as train_data:\n",
    "        with open('/home/md359230/DeepLearning/assignment3/data/validation.txt', 'w') as validation_data:\n",
    "            for counter, line in enumerate(sample_data):\n",
    "                if counter < 105378:\n",
    "                    train_data.write(line)            \n",
    "                else:\n",
    "                    validation_data.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105378\n"
     ]
    }
   ],
   "source": [
    "! cat ../data/train.txt | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26345\n"
     ]
    }
   ],
   "source": [
    "! cat ../data/validation.txt | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorpusPreprocessor(object):  \n",
    "    @staticmethod\n",
    "    def transform_text(text):\n",
    "        # Remove EOL character\n",
    "        text = text.replace('\\n', ' ')\n",
    "        \n",
    "        # Remove numbers\n",
    "        numbers = '1234567890'\n",
    "        for number in numbers:\n",
    "            text = text.replace(number, ' ')\n",
    "        \n",
    "        # Remove punctuation\n",
    "        for specialchar in punctuation:\n",
    "            text = text.replace(specialchar, ' ')\n",
    "            \n",
    "        # Remove double spaces\n",
    "        double_spaces = re.compile('\\s+')\n",
    "        text = re.sub(double_spaces, ' ', text)\n",
    "        \n",
    "        # Trim text\n",
    "        words = text.split(' ')\n",
    "        words = [word.lower() for word in words if word]\n",
    "        text = ' '.join(words)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    @staticmethod\n",
    "    def mask_text(text, corpus_dictionary):\n",
    "        MASK = 'MASK'\n",
    "        masked_sent = text.split()\n",
    "        selected_word_idx = random.randint(0, len(masked_sent) - 1)\n",
    "        if random.randint(0, 1) == 1:\n",
    "            original_word = masked_sent[selected_word_idx]\n",
    "            masked_sent[selected_word_idx] = MASK\n",
    "            return (masked_sent, original_word, selected_word_idx, 1)\n",
    "        else:\n",
    "            random_word = np.random.choice(corpus_dictionary)\n",
    "            masked_sent[selected_word_idx] = MASK\n",
    "            return (masked_sent, random_word, selected_word_idx, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'afdafs sa sfw gw g gfdsaf j'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CorpusPreprocessor.transform_text('AFDafs  41 2 5$#sa 24 Sfw15 gw g4gfdsaf j.    ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['MASK', 'ma', 'kota'], 'ala', 0, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CorpusPreprocessor.mask_text(CorpusPreprocessor.transform_text('Ala ma kota.'), ['aaa', 'bbb', 'ccc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLPDataSet(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.sentences = []\n",
    "        self.corpus_vocab = []\n",
    "        \n",
    "        # Load corpus from file\n",
    "        chars = set()\n",
    "        with open(file_path, 'r') as raw_data:\n",
    "            for line in raw_data:\n",
    "                line = CorpusPreprocessor.transform_text(line)\n",
    "                chars = chars | set(line)\n",
    "                self.sentences.append(line)\n",
    "        \n",
    "        # Create dict with all letters\n",
    "        self.chars = OrderedDict(zip(chars, (torch.zeros(len(chars)) for _ in range(len(chars)))))\n",
    "        for idx, key in enumerate(self.chars.keys()):\n",
    "            if key != ' ':\n",
    "                self.chars[key][idx] = 1.\n",
    "        \n",
    "        # Fill the dictionary with sample 20%\n",
    "        for sentence in self.sentences[:len(self.sentences) // 5]:\n",
    "            for word in sentence.split():\n",
    "                if len(word) >= 3:\n",
    "                    self.corpus_vocab.append(word)\n",
    "                    \n",
    "        self.corpus_vocab = list(set(self.corpus_vocab))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def _encode_word(self, word):\n",
    "        result = []\n",
    "        if word == 'MASK':\n",
    "            return result\n",
    "        \n",
    "        for letter in word:\n",
    "            result.append(self.chars[letter])\n",
    "    \n",
    "        return result\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sentence, word, idx, label = CorpusPreprocessor.mask_text(self.sentences[idx], self.corpus_vocab)\n",
    "        sentence = [self._encode_word(word) for word in sentence]\n",
    "        word = self._encode_word(word)\n",
    "        idx = torch.LongTensor([idx]).view(1)\n",
    "        label = torch.LongTensor([label]).view(1)\n",
    "        return sentence, word, idx, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = NLPDataSet('/home/md359230/DeepLearning/assignment3/data/train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = NLPDataSet('/home/md359230/DeepLearning/assignment3/data/validation.txt')\n",
    "data_test.chars = data_train.chars.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jego żołnierza i biedę można znaleźć w repertuarze polskich teatrów'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 9, 1, 0, 5, 7, 1, 11, 8, 7]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(len, data_train[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_collate(batch): \n",
    "    def stack_chars(word):\n",
    "        if len(word) > 1:\n",
    "            return torch.stack(word)\n",
    "        else:\n",
    "            if len(word) == 1:\n",
    "                return word[0].view(1, -1)\n",
    "            else:\n",
    "                return torch.zeros(1, 36)\n",
    "    \n",
    "    words = []\n",
    "    sentences = [] \n",
    "    words_length = []\n",
    "    sentences_length = []\n",
    "    idxs = []\n",
    "    labels = [] \n",
    "    for sentence, word, idx, label in batch: \n",
    "        words.append(word)\n",
    "        sentences.append(sentence)\n",
    "        words_length.append(len(word))\n",
    "        sentences_length.append([len(word) if len(word) > 0 else 1 for word in sentence])\n",
    "        idxs.append(idx)\n",
    "        labels.append(label) \n",
    "       \n",
    "    words = [stack_chars(word) for word in words]\n",
    "    words = utils_rnn.pad_sequence(words)\n",
    "    sentences = [utils_rnn.pad_sequence(list(map(stack_chars, sentence))) for sentence in sentences]\n",
    "    words_length = torch.LongTensor(words_length)\n",
    "    sentences_length = [torch.LongTensor(sentence) for sentence in sentences_length]\n",
    "    idxs = torch.stack(idxs)\n",
    "    labels = torch.stack(labels).squeeze(1)\n",
    "    return sentences, sentences_length, words, words_length, idxs,  labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(data_train,\n",
    "                              batch_size=1024,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=nlp_collate,\n",
    "                              num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_test = DataLoader(data_test,\n",
    "                             batch_size=1024,\n",
    "                             shuffle=True,\n",
    "                             collate_fn=nlp_collate,\n",
    "                             num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i, example in enumerate(data_train):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "CPU times: user 16.7 s, sys: 11.6 s, total: 28.4 s\n",
      "Wall time: 8min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, batch in enumerate(dataloader_train):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_layer(in_features, \n",
    "                 out_features, \n",
    "                 batchnorm_module='default',\n",
    "                 activation_function='relu', \n",
    "                 *args, \n",
    "                 **kwargs):\n",
    "    activation_functions = nn.ModuleDict([\n",
    "        ['lrelu', nn.LeakyReLU()],\n",
    "        ['relu', nn.ReLU()],\n",
    "        ['sigmoid', nn.Sigmoid()]\n",
    "    ])\n",
    "\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features, out_features, *args, **kwargs),\n",
    "        nn.BatchNorm1d(out_features),\n",
    "        activation_functions[activation_function]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearStack(nn.Module):\n",
    "    \"\"\"Class containing implementation of standard linear stack.\n",
    "    \"\"\"\n",
    "    def __init__(self, sizes, n_classes, *args, **kwargs):\n",
    "        super(LinearStack, self).__init__()\n",
    "        self.linear_layers = nn.ModuleList([linear_layer(in_size, out_size, *args, **kwargs)\n",
    "                                                   for in_size, out_size in zip(sizes, sizes[1:])])\n",
    "        self.linear_layers.append(nn.Linear(sizes[-1], n_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Method implemention linear stack forward pass.\n",
    "        :param x: Input tensor.\n",
    "        :return: Processed tensor.\"\"\"\n",
    "        for linear_layer in self.linear_layers:\n",
    "            x = linear_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbedder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(WordEmbedder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        words_input, lengths = x\n",
    "        words_input = utils_rnn.pack_padded_sequence(input=words_input, \n",
    "                                               lengths=lengths, \n",
    "                                               enforce_sorted=False)\n",
    "        out, _ = self.lstm(words_input)\n",
    "        result, _ = utils_rnn.pad_packed_sequence(out, \n",
    "                                            total_length=max(lengths).item())\n",
    "        idx = (lengths - 1).view(-1, 1)\\\n",
    "                           .expand(len(lengths), \n",
    "                                   self.hidden_size)\n",
    "        idx = idx.unsqueeze(0)\n",
    "        result = result.gather(0, idx).squeeze(0)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WordEmbedder(36, 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = next(iter(dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "example2 = example[2].to(device) \n",
    "example3 = example[3].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model((example2, example3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 100])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model((example[2], example[3]))\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, sentences_length = example[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([15, 100]),\n",
       " torch.Size([13, 100]),\n",
       " torch.Size([23, 100]),\n",
       " torch.Size([22, 100]),\n",
       " torch.Size([42, 100]),\n",
       " torch.Size([24, 100]),\n",
       " torch.Size([12, 100]),\n",
       " torch.Size([20, 100]),\n",
       " torch.Size([13, 100]),\n",
       " torch.Size([8, 100]),\n",
       " torch.Size([23, 100]),\n",
       " torch.Size([16, 100]),\n",
       " torch.Size([8, 100]),\n",
       " torch.Size([7, 100]),\n",
       " torch.Size([14, 100]),\n",
       " torch.Size([11, 100])]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = []\n",
    "for idx in range(len(sentences)):\n",
    "    embeddings.append(model((sentences[idx], sentences_length[idx])))\n",
    "\n",
    "[e.size() for e in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainLanguageModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size,\n",
    "                 embedding_size,\n",
    "                 hidden_size,\n",
    "                 num_layers,\n",
    "                 linear_sizes, \n",
    "                 n_classes):\n",
    "        super(MainLanguageModel, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.wordembedder = WordEmbedder(input_size=input_size, \n",
    "                                         hidden_size=embedding_size,\n",
    "                                         num_layers=num_layers)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            bidirectional=True)\n",
    "        self.fc = LinearStack(linear_sizes, \n",
    "                              n_classes,     \n",
    "                              batchnorm_module='default',\n",
    "                              activation_function='lrelu')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Create embeddings\n",
    "        sentences, sentences_length, words, words_length, idxs = x\n",
    "        embeddings = []\n",
    "        \n",
    "        for idx in range(len(sentences)):\n",
    "            embeddings.append(self.wordembedder((sentences[idx], sentences_length[idx])))\n",
    "                \n",
    "        masked_word_embeddings = self.wordembedder((words, words_length))\n",
    "        \n",
    "        # Feed RNN with sentence batch\n",
    "        lengths = torch.LongTensor([sl.size()[0] for sl in sentences_length])\n",
    "        sentence_batch = utils_rnn.pad_sequence(embeddings)        \n",
    "        sentence_batch = utils_rnn.pack_padded_sequence(input=sentence_batch, \n",
    "                                                        lengths=lengths, \n",
    "                                                        enforce_sorted=False)\n",
    "        \n",
    "        out, _ = self.lstm(sentence_batch)\n",
    "        result, _ = utils_rnn.pad_packed_sequence(out, \n",
    "                                                  total_length=max(lengths).item())\n",
    "        idx = (idxs).view(-1, 1)\\\n",
    "                    .expand(len(lengths), 2 * self.hidden_size)        \n",
    "        idx = idx.unsqueeze(0)\n",
    "        result = result.gather(0, idx).squeeze(0)\n",
    "        \n",
    "        joined_result = torch.cat((result, masked_word_embeddings), dim=1)\n",
    "        joined_result = self.fc(joined_result)\n",
    "            \n",
    "        # Return embeddings, masked_word_embeddings, sentences_length, idxs\n",
    "        return joined_result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'input_size': 36,\n",
    "    'embedding_size': 100,\n",
    "    'hidden_size': 50,\n",
    "    'num_layers': 2,\n",
    "    'linear_sizes': (200, 100),\n",
    "    'n_classes': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm = MainLanguageModel(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "mlm = mlm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = next(iter(dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, sentences_length, words, words_length, idxs, labels = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sentence.to(device) for sentence in sentences]\n",
    "sentences_length = [sl.to(device) for sl in sentences_length]\n",
    "words = words.to(device)\n",
    "words_length = words_length.to(device)\n",
    "idxs = idxs.to(device)\n",
    "labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 2])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = mlm((sentences, sentences_length, words, words_length, idxs))\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetTrainer(object):\n",
    "    def __init__(self, train_loader, test_loader):\n",
    "        self.trainloader = train_loader\n",
    "        self.testloader = test_loader\n",
    "        \n",
    "    def assess(self, net, test=True, use_gpu=False, device=None):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        loader = self.testloader if test else self.trainloader\n",
    "        for data in loader:\n",
    "            sentences, sentences_length, words, words_length, idxs, labels = data\n",
    "            if device is not None and (device.__str__() != \"cpu\") and use_gpu:\n",
    "                sentences = [sentence.to(device) for sentence in sentences]\n",
    "                sentences_length = [sl.to(device) for sl in sentences_length]\n",
    "                words = words.to(device)\n",
    "                words_length = words_length.to(device)\n",
    "                idxs = idxs.to(device)\n",
    "                labels = labels.to(device)\n",
    "            outputs = net((sentences, sentences_length, words, words_length, idxs))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        dataset_name = 'test' if test else 'train'\n",
    "        print('Accuracy of the network on {} {} sentences: {:2.4f} %'.format(\n",
    "            total, dataset_name, 100 * correct / total))         \n",
    "            \n",
    "    def train(self, \n",
    "              config, \n",
    "              n_epoch=5, \n",
    "              use_gpu=False, \n",
    "              resume_training=False, \n",
    "              net_path=None):\n",
    "        net = MainLanguageModel(**config)\n",
    "        \n",
    "        if resume_training:\n",
    "            net.load_state_dict(torch.load(net_path))          \n",
    "        \n",
    "        if use_gpu:\n",
    "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "            if device.__str__() != \"cpu\":\n",
    "                net.to(device)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(net.parameters(), lr=0.0002, amsgrad=True)\n",
    "\n",
    "        for epoch in range(n_epoch):\n",
    "            running_loss = 0.0\n",
    "            t = time.time()\n",
    "            net.train()\n",
    "            \n",
    "            for i, data in enumerate(self.trainloader, 0):\n",
    "                sentences, sentences_length, words, words_length, idxs,  labels = data\n",
    "                \n",
    "                if use_gpu:\n",
    "                    if(device.__str__() != \"cpu\"):\n",
    "                        sentences = [sentence.to(device) for sentence in sentences]\n",
    "                        sentences_length = [sl.to(device) for sl in sentences_length]\n",
    "                        words = words.to(device)\n",
    "                        words_length = words_length.to(device)\n",
    "                        idxs = idxs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                    \n",
    "                optimizer.zero_grad()\n",
    "                outputs = net((sentences, sentences_length, words, words_length, idxs))\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 10 == 9:\n",
    "                    now = datetime.datetime.now()\n",
    "                    print('[%s , %d, %5d] Loss: %.4f' %\n",
    "                          (now.strftime('%Y-%m-%d %H:%M:%S'), epoch + 1, i + 1, running_loss / 100))\n",
    "                    print('[%s , %d, %5d] Elapsed time: %2.4f s' %\n",
    "                          (now.strftime('%Y-%m-%d %H:%M:%S'), epoch + 1, i + 1, time.time() - t))\n",
    "                    running_loss = 0.0\n",
    "                    t = time.time()\n",
    "            \n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                if use_gpu:\n",
    "                    self.assess(net, use_gpu=True, device=device)\n",
    "                    #self.assess(net, test=False, use_gpu=True, device=device)                \n",
    "                else:\n",
    "                    self.assess(net)\n",
    "                    #self.assess(net, test=False)\n",
    "\n",
    "        return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"config = {\\n    'input_size': 36,\\n    'embedding_size': 50,\\n    'hidden_size': 25,\\n    'num_layers': 2,\\n    'linear_sizes': (100, 50, 25),\\n    'n_classes': 2\\n}\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"config = {\n",
    "    'input_size': 36,\n",
    "    'embedding_size': 50,\n",
    "    'hidden_size': 25,\n",
    "    'num_layers': 2,\n",
    "    'linear_sizes': (100, 50, 25),\n",
    "    'n_classes': 2\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'input_size': 36,\n",
    "    'embedding_size': 200,\n",
    "    'hidden_size': 100,\n",
    "        'num_layers': 1,\n",
    "    'linear_sizes': (400, 200, 100),\n",
    "    'n_classes': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = NetTrainer(dataloader_train, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/md359230/DeepLearning/assignment3/src/model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-06-04 10:53:54 , 1,    10] Loss: 0.0606\n",
      "[2019-06-04 10:53:54 , 1,    10] Elapsed time: 60.8704 s\n",
      "[2019-06-04 10:54:40 , 1,    20] Loss: 0.0580\n",
      "[2019-06-04 10:54:40 , 1,    20] Elapsed time: 46.4711 s\n",
      "[2019-06-04 10:55:30 , 1,    30] Loss: 0.0573\n",
      "[2019-06-04 10:55:30 , 1,    30] Elapsed time: 49.5096 s\n",
      "[2019-06-04 10:56:16 , 1,    40] Loss: 0.0554\n",
      "[2019-06-04 10:56:16 , 1,    40] Elapsed time: 46.2062 s\n",
      "[2019-06-04 10:57:04 , 1,    50] Loss: 0.0547\n",
      "[2019-06-04 10:57:04 , 1,    50] Elapsed time: 47.7139 s\n",
      "[2019-06-04 10:57:50 , 1,    60] Loss: 0.0558\n",
      "[2019-06-04 10:57:50 , 1,    60] Elapsed time: 46.6830 s\n",
      "[2019-06-04 10:58:36 , 1,    70] Loss: 0.0559\n",
      "[2019-06-04 10:58:36 , 1,    70] Elapsed time: 45.3392 s\n",
      "[2019-06-04 10:59:22 , 1,    80] Loss: 0.0551\n",
      "[2019-06-04 10:59:22 , 1,    80] Elapsed time: 46.1600 s\n",
      "[2019-06-04 11:00:08 , 1,    90] Loss: 0.0556\n",
      "[2019-06-04 11:00:08 , 1,    90] Elapsed time: 45.8003 s\n",
      "[2019-06-04 11:00:50 , 1,   100] Loss: 0.0545\n",
      "[2019-06-04 11:00:50 , 1,   100] Elapsed time: 42.8225 s\n",
      "Accuracy of the network on 26345 test sentences: 66.0277 %\n",
      "[2019-06-04 11:03:04 , 2,    10] Loss: 0.0551\n",
      "[2019-06-04 11:03:04 , 2,    10] Elapsed time: 62.1552 s\n",
      "[2019-06-04 11:03:51 , 2,    20] Loss: 0.0535\n",
      "[2019-06-04 11:03:51 , 2,    20] Elapsed time: 46.9589 s\n",
      "[2019-06-04 11:04:39 , 2,    30] Loss: 0.0533\n",
      "[2019-06-04 11:04:39 , 2,    30] Elapsed time: 48.0895 s\n",
      "[2019-06-04 11:05:27 , 2,    40] Loss: 0.0527\n",
      "[2019-06-04 11:05:27 , 2,    40] Elapsed time: 47.8612 s\n",
      "[2019-06-04 11:06:14 , 2,    50] Loss: 0.0525\n",
      "[2019-06-04 11:06:14 , 2,    50] Elapsed time: 47.0370 s\n",
      "[2019-06-04 11:07:00 , 2,    60] Loss: 0.0527\n",
      "[2019-06-04 11:07:00 , 2,    60] Elapsed time: 46.2485 s\n",
      "[2019-06-04 11:07:47 , 2,    70] Loss: 0.0532\n",
      "[2019-06-04 11:07:47 , 2,    70] Elapsed time: 46.7948 s\n",
      "[2019-06-04 11:08:35 , 2,    80] Loss: 0.0536\n",
      "[2019-06-04 11:08:35 , 2,    80] Elapsed time: 47.3722 s\n",
      "[2019-06-04 11:09:20 , 2,    90] Loss: 0.0529\n",
      "[2019-06-04 11:09:20 , 2,    90] Elapsed time: 44.9528 s\n",
      "[2019-06-04 11:10:02 , 2,   100] Loss: 0.0524\n",
      "[2019-06-04 11:10:02 , 2,   100] Elapsed time: 42.1620 s\n",
      "Accuracy of the network on 26345 test sentences: 69.7134 %\n"
     ]
    }
   ],
   "source": [
    "model = trainer.train(config, n_epoch=2, use_gpu=True, resume_training=True, net_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/md359230/DeepLearning/assignment3/src/model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'input_size': 36,\n",
    "    'embedding_size': 200,\n",
    "    'hidden_size': 100,\n",
    "    'num_layers': 1,\n",
    "    'linear_sizes': (400, 200, 100),\n",
    "    'n_classes': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/md359230/DeepLearning/assignment3/src/model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MainLanguageModel(\n",
       "  (wordembedder): WordEmbedder(\n",
       "    (lstm): LSTM(36, 200)\n",
       "  )\n",
       "  (lstm): LSTM(200, 100, bidirectional=True)\n",
       "  (fc): LinearStack(\n",
       "    (linear_layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=400, out_features=200, bias=True)\n",
       "        (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Linear(in_features=200, out_features=100, bias=True)\n",
       "        (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (2): Linear(in_features=100, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded = MainLanguageModel(**config)\n",
    "model_loaded.load_state_dict(torch.load(model_path))\n",
    "model_loaded.eval()\n",
    "model_loaded.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = NetTrainer(dataloader_train, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_loaded = trainer.train(config, n_epoch=3, use_gpu=True, resume_training=True, net_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on 26345 test sentences: 61.9169 %\n"
     ]
    }
   ],
   "source": [
    "trainer.assess(model_loaded, use_gpu=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~63.7616 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network visualzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLPVisualizer(object):\n",
    "    def __init__(self, \n",
    "                 vocabulary, \n",
    "                 dictionary, \n",
    "                 embedder,\n",
    "                 device):\n",
    "        self.vocabulary = vocabulary\n",
    "        self.dictionary = dictionary\n",
    "        self.embedder = embedder\n",
    "        self.device = device\n",
    "        \n",
    "        vocab_lengths = torch.LongTensor([len(word) for word in self.vocabulary])       \n",
    "        vector_vocab = [[self.dictionary[char] for char in word] for word in self.vocabulary]\n",
    "        vector_vocab = [self.stack_chars(word) for word in vector_vocab]\n",
    "        vector_vocab = utils_rnn.pad_sequence(vector_vocab)\n",
    "        vector_vocab, vocab_lengths = vector_vocab.to(self.device), vocab_lengths.to(self.device)\n",
    "        \n",
    "        out = self.embedder((vector_vocab, vocab_lengths))\n",
    "        out = out.cpu()\\\n",
    "                 .detach()\\\n",
    "                 .numpy()\n",
    "        self.tsne = TSNE(n_components=2, \n",
    "                    perplexity=30.0, \n",
    "                    n_iter=1000)\n",
    "        out = self.tsne.fit_transform(out)\n",
    "        self.embeddings = out\n",
    "        \n",
    "    @staticmethod\n",
    "    def stack_chars(word):\n",
    "        if len(word) > 1:\n",
    "            return torch.stack(word)\n",
    "        else:\n",
    "            if len(word) == 1:\n",
    "                return word[0].view(1, -1)\n",
    "            else:\n",
    "                return torch.zeros(1, 36)\n",
    "        \n",
    "    def find_most_similar_word(self, embedding, k=3):\n",
    "        normalized_embeddings = np.apply_along_axis(lambda x: x / np.sqrt((x * x).sum()), \n",
    "                                                1, \n",
    "                                                self.embeddings)\n",
    "        normalized_embedding = embedding / np.sqrt((embedding * embedding).sum())\n",
    "        idxs = np.argsort(normalized_embeddings @ normalized_embedding)[::-1][:k]\n",
    "        return [self.vocabulary[idx] for idx in list(idxs)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpv = NLPVisualizer(data_train.corpus_vocab[:2000], data_train.chars, model_loaded.wordembedder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=nlpv.embeddings[:, 0], y=nlpv.embeddings[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nosili ['nosili', 'gałązki', 'wschodni']\n",
      "zwiększasz ['zwiększasz', 'orzysz', 'zlewasz']\n",
      "hardware ['hardware', 'donohue', 'pike']\n",
      "tervueren ['pamięciowej', 'tervueren', 'kamienne']\n",
      "obydwu ['obydwu', 'żywiołu', 'nowiu']\n",
      "brussels ['brussels', 'gators', 'hawaii']\n",
      "poręcznym ['poręcznym', 'zróżnicowanym', 'strukturalnym']\n",
      "przesłanka ['przesłanka', 'układanka', 'dziedziczenia']\n",
      "technicznymi ['zespołami', 'słodyczami', 'technicznymi']\n",
      "singli ['singli', 'wymazywani', 'miękki']\n",
      "doznało ['doznało', 'skojarzyło', 'skupowanego']\n",
      "uporządkowania ['uporządkowania', 'przezimowania', 'przedpełka']\n",
      "marcel ['marcel', 'eksponując', 'dokonując']\n",
      "powtórnie ['powtórnie', 'swietnie', 'obrócenie']\n",
      "sdm ['sdm', 'promował', 'odszukaniem']\n",
      "wandalizm ['wandalizm', 'mechanizm', 'odłączył']\n",
      "ubocznych ['ubocznych', 'stawianych', 'mlecznych']\n",
      "publikujący ['oddzielający', 'publikujący', 'pokazujący']\n",
      "pomocowe ['pomocowe', 'szczęście', 'pine']\n",
      "nieżonaty ['nieżonaty', 'inflanty', 'ankiety']\n",
      "zaproponował ['zaproponował', 'mężem', 'symbolem']\n",
      "alexa ['alexa', 'tisserand', 'strickland']\n",
      "repnina ['ambona', 'repnina', 'krzęcina']\n",
      "oficerami ['oficerami', 'wielkanocnymi', 'piłkarzami']\n",
      "mężem ['zaproponował', 'mężem', 'symbolem']\n",
      "lubuskie ['lubuskie', 'zniesie', 'alpejskie']\n",
      "pudełkach ['pudełkach', 'słowiańskich', 'angielskich']\n",
      "skate ['skate', 'oeste', 'grote']\n",
      "upoważnienia ['upoważnienia', 'spółdzielnia', 'przedawnienia']\n",
      "średni ['średni', 'kancelarii', 'events']\n",
      "adwokacki ['adwokacki', 'zwierzaki', 'kontrolowali']\n",
      "projektodawcy ['projektodawcy', 'historycy', 'portugalczycy']\n",
      "wykrzyczała ['wykrzyczała', 'gąsior', 'inkwizytor']\n",
      "łożyć ['łożyć', 'umieć', 'słoń']\n",
      "mademoiselle ['mademoiselle', 'modlitwie', 'wychodźstwie']\n",
      "chrzestną ['chrzestną', 'przewodniczą', 'powołują']\n",
      "wiatrowej ['premierowej', 'długotrwałej', 'wiatrowej']\n",
      "rozrywka ['rozrywka', 'holowania', 'sofia']\n",
      "eskadra ['eskadra', 'operatora', 'artura']\n",
      "wystawiając ['wystawiając', 'wskazując', 'oddalając']\n",
      "niewłaściwe ['niewłaściwe', 'kadrowe', 'kredowe']\n",
      "oferuję ['oferuję', 'trzyrundowe', 'południowe']\n",
      "inflanty ['inflanty', 'nieżonaty', 'lokaty']\n",
      "zabawiał ['zabawiał', 'pamietam', 'ułatwiał']\n",
      "storage ['storage', 'bezkrwawe', 'eddie']\n",
      "zboczu ['zboczu', 'gwaru', 'wyrazu']\n",
      "arcymistrza ['arcymistrza', 'powiecka', 'sofia']\n",
      "hroszówce ['hroszówce', 'nadwyżce', 'służące']\n",
      "rozsądnych ['rozsądnych', 'przewidywanych', 'dentystycznych']\n",
      "danin ['danin', 'zawin', 'gmin']\n",
      "kompetentnych ['kompetentnych', 'okalający', 'albańczycy']\n",
      "incumbent ['incumbent', 'rodzimych', 'znaczących']\n",
      "kółek ['kółek', 'sobczak', 'zderzak']\n",
      "polecenie ['polecenie', 'relatywnie', 'obarczanie']\n",
      "połaciach ['połaciach', 'osadach', 'sukcesach']\n",
      "procesu ['procesu', 'rozpatrywaniu', 'meldowaniu']\n",
      "przyjemnoci ['wiadomości', 'przyjemnoci', 'zdawalności']\n",
      "drinków ['ładunków', 'drinków', 'minerałów']\n",
      "ponosił ['ponosił', 'odstąpił', 'szkolił']\n",
      "yoony ['yoony', 'krzesiny', 'swatawy']\n",
      "gabinetach ['gabinetach', 'modlitwach', 'rozrachunkach']\n",
      "ustalany ['ustalany', 'niezależny', 'ukazały']\n",
      "wrocławska ['domniemania', 'wrocławska', 'naświetlania']\n",
      "prostej ['prostej', 'natłuszczone', 'zastępczej']\n",
      "smigłowce ['smigłowce', 'zaproponuje', 'osostowicz']\n",
      "kończy ['kończy', 'dotyczy', 'parzelniczy']\n",
      "biegłych ['biegłych', 'umarłych', 'portowych']\n",
      "kilkakrotnie ['kilkakrotnie', 'sprzeczne', 'poręczne']\n",
      "pogranicza ['pogranicza', 'dobkiewicza', 'bartosiewicza']\n",
      "inch ['inch', 'bwsh', 'lynch']\n",
      "wad ['wad', 'red', 'nkwd']\n",
      "astronomii ['astronomii', 'kardiologii', 'wizji']\n",
      "przygotowany ['przygotowany', 'wprowadzały', 'toboły']\n",
      "twierdza ['twierdza', 'pacyfka', 'dąbrówka']\n",
      "achievements ['achievements', 'wizji', 'hestii']\n",
      "skleić ['skleić', 'mielić', 'naruszać']\n",
      "okupantów ['okupantów', 'kontynentów', 'quadów']\n",
      "instytutami ['określającymi', 'śluzowymi', 'flagship']\n",
      "odpadła ['odpadła', 'gotowego', 'fiano']\n",
      "lynch ['lynch', 'inch', 'bwsh']\n",
      "lifetime ['lifetime', 'zapewnie', 'prokuratorskie']\n",
      "trudniejsza ['wciskania', 'trudniejsza', 'grania']\n",
      "przesadzić ['dopisywać', 'przesadzić', 'mordować']\n",
      "rinpocze ['rinpocze', 'walce', 'cleese']\n",
      "rysunku ['rysunku', 'batalionu', 'hellmanna']\n",
      "zrobiła ['zrobiła', 'siewnego', 'wróciło']\n",
      "wkroczenia ['wkroczenia', 'dickensa', 'uzależnienia']\n",
      "chuchnął ['chuchnął', 'kolegom', 'radził']\n",
      "przebicia ['przebicia', 'przyłącza', 'zawarcia']\n",
      "miarkę ['miarkę', 'owsiankę', 'naukę']\n",
      "kusterdingen ['kusterdingen', 'kunterstein', 'amnon']\n",
      "aklamacją ['aklamacją', 'odrębną', 'ustawodawczą']\n",
      "nadzianą ['mieszkalną', 'nadzianą', 'pokazują']\n",
      "górny ['górny', 'sony', 'plecy']\n",
      "udzielaniu ['udzielaniu', 'zysku', 'salonu']\n",
      "fala ['fala', 'rozwija', 'mówca']\n",
      "osadach ['osadach', 'połaciach', 'sukcesach']\n",
      "wybudowanie ['wybudowanie', 'zgłaszanie', 'uważne']\n",
      "sami ['sami', 'buenos', 'maxi']\n",
      "ekologiczną ['ekologiczną', 'uzasadniają', 'reklamą']\n"
     ]
    }
   ],
   "source": [
    "for i in range(100, 200):\n",
    "    print(nlpv.vocabulary[i] ,nlpv.find_most_similar_word(nlpv.embeddings[i, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jeżelibyśmy'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 2\n",
    "nlpv.vocabulary[np.argmax((out @ out[idx, :]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def visualize_words(self):\\n    vocab_lengths = torch.LongTensor([len(word) for word in self.vocabulary])       \\n    vector_vocab = [[self.dictionary[char] for char in word] for word in self.vocabulary]\\n    vector_vocab = [self.stack_chars(word) for word in vector_vocab]\\n    vector_vocab = utils_rnn.pad_sequence(vector_vocab)\\n    vector_vocab, vocab_lengths = vector_vocab.to(self.device), vocab_lengths.to(self.device)\\n    \\n    out = self.embedder((vector_vocab, vocab_lengths))\\n    out = out.cpu().detach().numpy()\\n    out = self.tsne.fit_transform(out)\\n    \\n    return out'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \"\"\"def visualize_words(self):\n",
    "        vocab_lengths = torch.LongTensor([len(word) for word in self.vocabulary])       \n",
    "        vector_vocab = [[self.dictionary[char] for char in word] for word in self.vocabulary]\n",
    "        vector_vocab = [self.stack_chars(word) for word in vector_vocab]\n",
    "        vector_vocab = utils_rnn.pad_sequence(vector_vocab)\n",
    "        vector_vocab, vocab_lengths = vector_vocab.to(self.device), vocab_lengths.to(self.device)\n",
    "        \n",
    "        out = self.embedder((vector_vocab, vocab_lengths))\n",
    "        out = out.cpu().detach().numpy()\n",
    "        out = self.tsne.fit_transform(out)\n",
    "        \n",
    "        return out\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = set()\n",
    "corpus_words = set()\n",
    "lens = list()\n",
    "with open('/home/md359230/DeepLearning/assignment3/data/task3_sample.txt', 'r') as sample_data:\n",
    "    for line in sample_data:\n",
    "        line = CorpusPreprocessor.transform_text(line)\n",
    "        lens.append(len(line))\n",
    "        chars = chars | set(line)\n",
    "        words = line.split()\n",
    "        corpus_words = corpus_words | set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7.0255e+04, 2.5162e+04, 3.7240e+03, 6.8500e+02, 1.3800e+02,\n",
       "        2.6000e+01, 5.0000e+00, 4.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
       " array([   4.,  137.,  270.,  403.,  536.,  669.,  802.,  935., 1068.,\n",
       "        1201., 1334.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'po wybuchu ii wojny światowej podczas kampanii wrześniowej sprawował stanowisko dowódcy pułku piechoty'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = 'Po wybuchu II wojny światowej 1939 podczas kampanii wrześniowej sprawował stanowisko dowódcy 78 pułku piechoty.'\n",
    "cp.transform_text(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        self.dictionary = OrderedDict()\n",
    "        self.corpus_path = corpus_path\n",
    "        with open(corpus_path, 'r') as corpus:\n",
    "            for line in corpus:\n",
    "                self.dictionary[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'afs 41 2 5$#sa 24 Sfw15 gw g4gfdsaf j'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_spaces = re.compile('\\s+')\n",
    "re.sub(double_spaces, ' ', 'afs  41 2 5$#sa 24 Sfw15 gw g4gfdsaf j')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([torch.Size([4, 100]),\n",
       "  torch.Size([6, 100]),\n",
       "  torch.Size([5, 100]),\n",
       "  torch.Size([14, 100]),\n",
       "  torch.Size([9, 100]),\n",
       "  torch.Size([18, 100]),\n",
       "  torch.Size([6, 100]),\n",
       "  torch.Size([22, 100]),\n",
       "  torch.Size([9, 100]),\n",
       "  torch.Size([11, 100]),\n",
       "  torch.Size([6, 100]),\n",
       "  torch.Size([13, 100]),\n",
       "  torch.Size([8, 100]),\n",
       "  torch.Size([6, 100]),\n",
       "  torch.Size([25, 100]),\n",
       "  torch.Size([16, 100])],\n",
       " torch.Size([16, 100]))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o.size() for o in out[0]], out[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_words= out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = torch.LongTensor([o.size()[0] for o in out[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_input = utils_rnn.pad_sequence(out[0])\n",
    "\n",
    "words_input.size()\n",
    "\n",
    "packed_input = utils_rnn.pack_padded_sequence(input=words_input, \n",
    "                                             lengths=lengths, \n",
    "                                             enforce_sorted=False)\n",
    "\n",
    "lstm2 = nn.LSTM(input_size=100,\n",
    "                hidden_size=50,\n",
    "                bidirectional=True)\n",
    "\n",
    "out, _ = lstm2(packed_input)\n",
    "result, _ = utils_rnn.pad_packed_sequence(out, \n",
    "                                    total_length=max(lengths).item())\n",
    "idx = (idxs).view(-1, 1)\\\n",
    "                                     .expand(len(lengths), \n",
    "                                             100)\n",
    "idx = idx.unsqueeze(0)\n",
    "result_final = result.gather(0, idx).squeeze(0)\n",
    "\n",
    "result_final.size()\n",
    "\n",
    "joined_information = torch.cat((result_final, masked_words), dim=1)\n",
    "\n",
    "fc = LinearStack((200, 100), 2)\n",
    "\n",
    "final = fc(joined_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0788,  0.2965],\n",
       "        [ 0.3925,  0.1174],\n",
       "        [ 0.0335, -0.1361],\n",
       "        [ 0.2581,  0.1808],\n",
       "        [ 0.1624,  0.1204],\n",
       "        [ 0.2782,  0.2596],\n",
       "        [-0.0378,  0.1297],\n",
       "        [ 0.5840,  0.2376],\n",
       "        [ 0.2791,  0.1616],\n",
       "        [ 0.5826,  0.6866],\n",
       "        [ 0.0406,  0.0681],\n",
       "        [ 0.5139, -0.0842],\n",
       "        [-0.0675,  0.0903],\n",
       "        [ 0.1305,  0.1092],\n",
       "        [ 0.4054,  0.4469],\n",
       "        [ 0.0595,  0.0318]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6807, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "loss(final, labels.squeeze(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
